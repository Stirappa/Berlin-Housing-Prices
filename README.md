# ğŸ™ï¸ Berlin Housing Prices â€” Machine Learning Project
### *Inspired by the Kaggle â€œHouse Prices: Advanced Regression Techniquesâ€ Competition*

This project is inspired by the well-known Kaggle Housing Prices competition, but instead of using the Iowa dataset, the goal here is to apply a similar machine-learning pipeline specifically to the **Berlin real-estate market**.

The project focuses on understanding what drives apartment and house prices in Berlin, preparing a clean dataset, performing exploratory data analysis (EDA), engineering useful real-estate features, and building predictive models capable of estimating property prices.

This repository is ideal for anyone learning:

- Data cleaning  
- Feature engineering  
- Categorical encoding  
- Regression modeling  
- Real-world ML workflows  
- Jupyter Notebook data science projects  

---

## ğŸ“¦ Project Files

```
â”œâ”€â”€ Berlin Housing Prices.ipynb     # Main notebook
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ LICENSE
â””â”€â”€ real_estate_listings_clean.csv  
```

---

## ğŸ¯ Project Motivation

Berlin is one of Europeâ€™s most dynamic and rapidly growing housing markets. Factors influencing prices include:

- Location (Bezirk / district)  
- Apartment size  
- Age of building  
- Energy efficiency  
- Number of rooms  
- Zipcode  
- price per area

Inspired by the Kaggle house price regression challenge, the main goals were:

1. Recreate a similar machine learning workflow  
2. Adapt it to Berlin housing characteristics  
3. Train models that predict real-world property prices  
4. Practice and demonstrate end-to-end data science skills  

---

## ğŸ§¹ 1. Data Cleaning & Preparation

### âœ” Handling missing values
Missing data was not found. But features has been encoded, or removed depending on the importance of the feature.

### âœ” Removing irrelevant columns
Columns that provide no predictive valueâ€”like listing URLsâ€”were removed.

### âœ” Standardizing and encoding categorical features
Districts, energy-efficiency labels, and building types were cleaned and encoded using **Numeric Representation**.

### âœ” Feature normalization
Applied where necessary depending on the model.

---

## ğŸ“Š 2. Exploratory Data Analysis (EDA)

Visualizations included:

- Price distribution  
- Surface area and room distributions  
- Correlation heatmap  
- District-level comparisons  
- Outlier detection  

### Key Insights

- District strongly influences price  
- Area (mÂ²) is the strongest numeric predictor  
- Energy-efficient homes tend to be more expensive  
- Luxury districts show notable outliers  

---

## ğŸ§± 3. Feature Engineering

Engineered or transformed features include:

- Energy label â†’ numerical scoring  
- Price per square meter  
- Building age categories  
- Room count categories  

Effective feature engineering significantly improved model performance.

---

## ğŸ¤– 4. Machine Learning Models

Models evaluated:

### ğŸ”¹ Gradient Boosting Regressor  
Captures complex, non-linear patterns and handles encoding well.

### ğŸ”¹ Optional Future Models  
- LightGBM  

## ğŸ“ 5. Evaluation Metrics

To evaluate the models, we used:

- **MAE** â€” Mean Absolute Error  
- **RMSE** â€” Root Mean Squared Error  

---

## ğŸ§¾ 6. Results Summary

General findings:

- Random Forest performed best  
- Area (mÂ²) and district were the most influential features  
- Energy efficiency had moderate influence  
- Feature engineering improved accuracy significantly  

---

## ğŸ”® Future Improvements

- Add geographic coordinates  
- Build interactive maps (Folium, Plotly)  
- Use hyperparameter tuning  
- Train advanced boosting models  
- Deploy a Streamlit price predictor app  

---

## ğŸ™Œ Acknowledgements

- Inspired by the Kaggle Housing Price Competition  
- Built with Python, Pandas, Matplotlib, Scikit-Learn  
- Thanks to the open-source community  

